{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Real-Time Facial Emotion Recognition (ITS - Computer Vision)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Content <a id = 0></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Introduction](#1)\n",
    "- [Setup](#2)\n",
    "- [Dataset](#3)\n",
    "- [Data pipeline](#4)\n",
    "- [Preprocessing](#5)\n",
    "- [Train/val split](#6)\n",
    "- [Training utils](#7)\n",
    "- [Model](#8)\n",
    "- [Train](#9)\n",
    "- [Load & history](#10)\n",
    "- [Curves](#11)\n",
    "- [Test eval](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id = 1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "Goal: build a real-time facial emotion recognition demo for the ITS Computer Vision course. The pipeline covers face detection, preprocessing, emotion classification, and on-screen visualization (bounding box, label, confidence, FPS).\n",
    "\n",
    "- Target classes: angry, disgust, fear, happy, sad, surprise, neutral.\n",
    "- Real-time inference loop: camera → face detection → preprocessing (crop/align, normalize, resize) → emotion model → optional smoothing → visualization.\n",
    "\n",
    "### Dataset and Model\n",
    "\n",
    "- Primary dataset: FER2013 (see `data/link_to_data.txt` for the Kaggle source).\n",
    "- 48×48 grayscale images; naturally imbalanced classes; consider augmentation and temporal smoothing.\n",
    "- Suggested model: lightweight CNN (Keras/TensorFlow) or PyTorch equivalent. Target ≥ 20 FPS on a mid-range laptop.\n",
    "\n",
    "### Tech Stack (suggested)\n",
    "\n",
    "- Python 3.9+\n",
    "- OpenCV for video I/O and basic CV ops\n",
    "- TensorFlow/Keras or PyTorch for the emotion model\n",
    "- NumPy/Pandas/Matplotlib/Seaborn for preprocessing/analysis\n",
    "\n",
    "### Ethical Use and Limitations\n",
    "\n",
    "- Emotion recognition is probabilistic and sensitive to lighting, pose, occlusions, and dataset bias.\n",
    "- Educational use only; do not use for high-stakes decisions; obtain consent before capturing or analyzing video.\n",
    "\n",
    "### Roadmap\n",
    "\n",
    "1) Use the webcam to extract the face.\n",
    "2) Convert the face crop to match the dataset style.\n",
    "3) Train on FER2013 (or load a pretrained model).\n",
    "4) Run the webcam image through the model.\n",
    "5) Overlay the predicted label and confidence on the face box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup <a id = 2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:19.939583Z",
     "iopub.status.busy": "2023-06-03T09:11:19.939209Z",
     "iopub.status.idle": "2023-06-03T09:11:31.069784Z",
     "shell.execute_reply": "2023-06-03T09:11:31.068761Z",
     "shell.execute_reply.started": "2023-06-03T09:11:19.939543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix \u001b[38;5;28;01mas\u001b[39;00m sk_confusion_matrix\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Tensorflow Library\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization, Dropout\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Basic Python Packages\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Numpy Library\n",
    "import numpy as np\n",
    "\n",
    "# Pandas Library and Settings\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization Libraries (Matplotlib, Seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SKLearn Libarary\n",
    "from sklearn.metrics import confusion_matrix as sk_confusion_matrix\n",
    "\n",
    "# Tensorflow Library\n",
    "import tensorflow as tf\n",
    "    \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from keras.metrics.accuracy_metrics import Accuracy, CategoricalAccuracy\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:31.073542Z",
     "iopub.status.busy": "2023-06-03T09:11:31.072036Z",
     "iopub.status.idle": "2023-06-03T09:11:31.392672Z",
     "shell.execute_reply": "2023-06-03T09:11:31.391376Z",
     "shell.execute_reply.started": "2023-06-03T09:11:31.073492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:31.395125Z",
     "iopub.status.busy": "2023-06-03T09:11:31.394398Z",
     "iopub.status.idle": "2023-06-03T09:11:31.404015Z",
     "shell.execute_reply": "2023-06-03T09:11:31.402802Z",
     "shell.execute_reply.started": "2023-06-03T09:11:31.395047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:31.406503Z",
     "iopub.status.busy": "2023-06-03T09:11:31.405759Z",
     "iopub.status.idle": "2023-06-03T09:11:35.774294Z",
     "shell.execute_reply": "2023-06-03T09:11:35.773389Z",
     "shell.execute_reply.started": "2023-06-03T09:11:31.40646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0,1\"\n",
    "\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing tensorflow settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.778043Z",
     "iopub.status.busy": "2023-06-03T09:11:35.777698Z",
     "iopub.status.idle": "2023-06-03T09:11:35.783928Z",
     "shell.execute_reply": "2023-06-03T09:11:35.782732Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.777997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset <a id = 3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the dataset directory and check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.786741Z",
     "iopub.status.busy": "2023-06-03T09:11:35.786175Z",
     "iopub.status.idle": "2023-06-03T09:11:35.804161Z",
     "shell.execute_reply": "2023-06-03T09:11:35.803151Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.786708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_directory = \"../data/archive\"\n",
    "\n",
    "print(f\"{os.listdir(data_directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.805707Z",
     "iopub.status.busy": "2023-06-03T09:11:35.805049Z",
     "iopub.status.idle": "2023-06-03T09:11:35.811976Z",
     "shell.execute_reply": "2023-06-03T09:11:35.81088Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.805674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_directory = os.path.join(data_directory, \"train\")\n",
    "test_directory = os.path.join(data_directory, \"test\")\n",
    "\n",
    "print(f\"Data directory     {data_directory}\")\n",
    "print(f\"Train directory    {train_directory}\")\n",
    "print(f\"Test directory     {test_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List train/test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.814194Z",
     "iopub.status.busy": "2023-06-03T09:11:35.813799Z",
     "iopub.status.idle": "2023-06-03T09:11:35.827395Z",
     "shell.execute_reply": "2023-06-03T09:11:35.826259Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.814149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"{os.listdir(train_directory)}\")\n",
    "print(f\"{os.listdir(test_directory)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seven classes. Count images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.830114Z",
     "iopub.status.busy": "2023-06-03T09:11:35.829405Z",
     "iopub.status.idle": "2023-06-03T09:11:35.835678Z",
     "shell.execute_reply": "2023-06-03T09:11:35.834713Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.830082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "expressions_list = os.listdir(train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:35.83833Z",
     "iopub.status.busy": "2023-06-03T09:11:35.837474Z",
     "iopub.status.idle": "2023-06-03T09:11:36.545921Z",
     "shell.execute_reply": "2023-06-03T09:11:36.544926Z",
     "shell.execute_reply.started": "2023-06-03T09:11:35.838297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_info_df = pd.DataFrame(columns=[\"Expression\", \"Size\", \"Proportion %\"])\n",
    "train_expression_size = []\n",
    "\n",
    "for expression in expressions_list:\n",
    "    \n",
    "    index = expressions_list.index(expression)\n",
    "    \n",
    "    train_expression_directory = os.path.join(train_directory, expression)\n",
    "    train_expression_size.append(len(os.listdir(train_expression_directory)))\n",
    "    \n",
    "train_expression_proportion = [round((expression_size / sum(train_expression_size)) * 100, 2)\\\n",
    "                               for expression_size in train_expression_size]\n",
    "\n",
    "train_dataset_info_df[\"Expression\"] = expressions_list\n",
    "train_dataset_info_df[\"Size\"] = train_expression_size\n",
    "train_dataset_info_df[\"Proportion %\"] = train_expression_proportion\n",
    "\n",
    "total_size = train_dataset_info_df[\"Size\"].sum()\n",
    "total_proportion = train_dataset_info_df[\"Proportion %\"].sum()\n",
    "\n",
    "total_row = pd.DataFrame({\"Expression\": [\"Total\"],\n",
    "                          \"Size\": [total_size],\n",
    "                          \"Proportion %\": [total_proportion]})\n",
    "\n",
    "train_dataset_info_df = pd.concat([train_dataset_info_df, total_row], ignore_index=True)\n",
    "\n",
    "train_dataset_info_df = train_dataset_info_df.style\n",
    "train_dataset_info_df = train_dataset_info_df.apply(lambda x: ['background-color: green' if\\\n",
    "                                                    i == len(x)-1 else ''\\\n",
    "                                                    for i in range(len(x))], axis=0)\n",
    "\n",
    "train_dataset_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:36.548758Z",
     "iopub.status.busy": "2023-06-03T09:11:36.547603Z",
     "iopub.status.idle": "2023-06-03T09:11:37.579403Z",
     "shell.execute_reply": "2023-06-03T09:11:37.578094Z",
     "shell.execute_reply.started": "2023-06-03T09:11:36.548721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset_info_df = pd.DataFrame(columns=[\"Expression\", \"Size\", \"Proportion %\"])\n",
    "test_expression_size = []\n",
    "\n",
    "for expression in expressions_list:\n",
    "    \n",
    "    index = expressions_list.index(expression)\n",
    "    \n",
    "    test_expression_directory = os.path.join(test_directory, expression)\n",
    "    test_expression_size.append(len(os.listdir(test_expression_directory)))\n",
    "    \n",
    "test_expression_proportion = [round((expression_size / sum(test_expression_size)) * 100, 2)\\\n",
    "                              for expression_size in test_expression_size]\n",
    "\n",
    "test_dataset_info_df[\"Expression\"] = expressions_list\n",
    "test_dataset_info_df[\"Size\"] = test_expression_size\n",
    "test_dataset_info_df[\"Proportion %\"] = test_expression_proportion\n",
    "\n",
    "total_size = test_dataset_info_df[\"Size\"].sum()\n",
    "total_proportion = test_dataset_info_df[\"Proportion %\"].sum()\n",
    "\n",
    "total_row = pd.DataFrame({\"Expression\": [\"Total\"],\n",
    "                          \"Size\": [total_size],\n",
    "                          \"Proportion %\": [total_proportion]})\n",
    "\n",
    "test_dataset_info_df = pd.concat([test_dataset_info_df, total_row], ignore_index=True)\n",
    "\n",
    "test_dataset_info_df = test_dataset_info_df.style\n",
    "test_dataset_info_df = test_dataset_info_df.apply(lambda x: ['background-color: green'\\\n",
    "                                                  if i == len(x)-1 else ''\\\n",
    "                                                  for i in range(len(x))], axis=0)\n",
    "\n",
    "test_dataset_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that about 20% of the data is in the test set and the rest are in the train set.\n",
    "\n",
    "The training dataset is imbalanced, with different proportions for each expression category.</br>\n",
    "Imbalanced datasets can pose challenges during training, as the model may be biased towards the majority class(es) and struggle to accurately classify the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the distribution of different facial expressions images the same in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:37.582939Z",
     "iopub.status.busy": "2023-06-03T09:11:37.582502Z",
     "iopub.status.idle": "2023-06-03T09:11:38.03916Z",
     "shell.execute_reply": "2023-06-03T09:11:38.038018Z",
     "shell.execute_reply.started": "2023-06-03T09:11:37.5829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "axes_font = {\"family\" : \"arial\", \"color\" : \"grey\", \"weight\" : \"bold\", \"size\" : 12}\n",
    "\n",
    "sorted_index = np.argsort(train_expression_size)[::-1]\n",
    "\n",
    "values = np.array(train_expression_size)[sorted_index]\n",
    "label = np.array(expressions_list)[sorted_index]\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(values)))\n",
    "\n",
    "plt.bar(label, values, color=colors)\n",
    "\n",
    "plt.xlabel(\"Expressions\", fontdict=axes_font)\n",
    "plt.ylabel(\"Train Expression Size\", fontdict=axes_font)\n",
    "plt.title(\"Train Expression Size by Expression\", fontdict=title_font)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:38.041842Z",
     "iopub.status.busy": "2023-06-03T09:11:38.041139Z",
     "iopub.status.idle": "2023-06-03T09:11:38.389422Z",
     "shell.execute_reply": "2023-06-03T09:11:38.388473Z",
     "shell.execute_reply.started": "2023-06-03T09:11:38.041802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "axes_font = {\"family\" : \"arial\", \"color\" : \"grey\", \"weight\" : \"bold\", \"size\" : 12}\n",
    "\n",
    "sorted_index = np.argsort(test_expression_size)[::-1]\n",
    "\n",
    "values = np.array(test_expression_size)[sorted_index]\n",
    "label = np.array(expressions_list)[sorted_index]\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(values)))\n",
    "\n",
    "plt.bar(label, values, color=colors)\n",
    "\n",
    "plt.xlabel(\"Expressions\", fontdict=axes_font)\n",
    "plt.ylabel(\"Test Expression Size\", fontdict=axes_font)\n",
    "plt.title(\"Test Expression Size by Expression\", fontdict=title_font)\n",
    "\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check one image for each expression to get better understanding of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:38.398098Z",
     "iopub.status.busy": "2023-06-03T09:11:38.397042Z",
     "iopub.status.idle": "2023-06-03T09:11:39.799687Z",
     "shell.execute_reply": "2023-06-03T09:11:39.798613Z",
     "shell.execute_reply.started": "2023-06-03T09:11:38.398058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(expressions_list), figsize=(len(expressions_list) * 4, 4))\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(expressions_list):\n",
    "    \n",
    "    expression = expressions_list[i]\n",
    "\n",
    "    expression_directory = os.path.join(train_directory, expression)\n",
    "    images_list = os.listdir(expression_directory)\n",
    "    \n",
    "    image_directory = os.path.join(expression_directory, random.choice(images_list))\n",
    "    \n",
    "    image = cv2.imread(image_directory, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "    axes[i].imshow(image, cmap=\"gray\")\n",
    "    axes[i].set_title(expression, fontdict=title_font)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Let's get deeper to check the images as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:39.801233Z",
     "iopub.status.busy": "2023-06-03T09:11:39.800852Z",
     "iopub.status.idle": "2023-06-03T09:11:39.808118Z",
     "shell.execute_reply": "2023-06-03T09:11:39.806911Z",
     "shell.execute_reply.started": "2023-06-03T09:11:39.801198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Images shape is: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the last step, we want to get assured that all field have the same format type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:39.81123Z",
     "iopub.status.busy": "2023-06-03T09:11:39.810269Z",
     "iopub.status.idle": "2023-06-03T09:11:39.865186Z",
     "shell.execute_reply": "2023-06-03T09:11:39.864054Z",
     "shell.execute_reply.started": "2023-06-03T09:11:39.811194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "formats = []\n",
    "\n",
    "for dir in [train_directory, test_directory]:\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    print(f\"Checking {dir.split('/')[1]} data:\")\n",
    "    \n",
    "    while i < len(expressions_list):\n",
    "        \n",
    "        expression = expressions_list[i]\n",
    "\n",
    "        expression_directory = os.path.join(dir, expression)\n",
    "        images_list = os.listdir(expression_directory)\n",
    "        \n",
    "        for image in images_list:\n",
    "                    \n",
    "            format = image.split(\".\")[1]\n",
    "            \n",
    "            if format not in formats:\n",
    "                formats.append(format)\n",
    "\n",
    "        print(f\"    {expression} Checked.\")\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(f\"File formats are: {formats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything is ok, we can get further and build a data pypeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data pipeline <a id = 4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's create a dataset from image files to use them for training the neural network.</br>\n",
    "In this step, we also label the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:39.868053Z",
     "iopub.status.busy": "2023-06-03T09:11:39.867195Z",
     "iopub.status.idle": "2023-06-03T09:11:51.118149Z",
     "shell.execute_reply": "2023-06-03T09:11:51.117066Z",
     "shell.execute_reply.started": "2023-06-03T09:11:39.868013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(train_directory,\n",
    "                                                           image_size=(48, 48),\n",
    "                                                           batch_size=64,\n",
    "                                                           color_mode=\"grayscale\")\n",
    "\n",
    "print(f\"Data type is:       {type(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calsses are assigned like the way below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:51.12228Z",
     "iopub.status.busy": "2023-06-03T09:11:51.119541Z",
     "iopub.status.idle": "2023-06-03T09:11:51.130137Z",
     "shell.execute_reply": "2023-06-03T09:11:51.128868Z",
     "shell.execute_reply.started": "2023-06-03T09:11:51.12224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "expressions_list = data.class_names\n",
    "\n",
    "expressions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the data, we should iterate over it using the numpy iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:51.13314Z",
     "iopub.status.busy": "2023-06-03T09:11:51.132266Z",
     "iopub.status.idle": "2023-06-03T09:11:51.198949Z",
     "shell.execute_reply": "2023-06-03T09:11:51.197935Z",
     "shell.execute_reply.started": "2023-06-03T09:11:51.133102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()\n",
    "\n",
    "data_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this iterated data, we have to get batch from it to feed the neural network.</br>\n",
    "This step will be completed in the training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:51.201219Z",
     "iopub.status.busy": "2023-06-03T09:11:51.20083Z",
     "iopub.status.idle": "2023-06-03T09:11:52.41382Z",
     "shell.execute_reply": "2023-06-03T09:11:52.412709Z",
     "shell.execute_reply.started": "2023-06-03T09:11:51.201183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = data_iterator.next()\n",
    "\n",
    "print(f\"Each batch has {len(batch)} parts of data.\")\n",
    "print(f\"Each batch's images part has the shape of {batch[0].shape}\")\n",
    "print(f\"Each batch's images part has the shape of {batch[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that each batch has two parts of data, images and labels.</br>\n",
    "Images part has 32 images which are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further, let's check the train dataset by their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:52.415904Z",
     "iopub.status.busy": "2023-06-03T09:11:52.415556Z",
     "iopub.status.idle": "2023-06-03T09:11:55.253953Z",
     "shell.execute_reply": "2023-06-03T09:11:55.252764Z",
     "shell.execute_reply.started": "2023-06-03T09:11:52.415873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "\n",
    "print(\"Facial expressions are:\")\n",
    "\n",
    "for expression in expressions_list:\n",
    "    print(f\"    {expressions_list.index(expression)}. {expression}\")\n",
    "\n",
    "indexes = np.random.randint(0, batch[0].shape[0], 14)\n",
    "\n",
    "fig, axes = plt.subplots(2, 7, figsize=(28, 8))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for index in indexes:\n",
    "    \n",
    "    axes[i, j].imshow(batch[0][index].astype(int), cmap=\"gray\")\n",
    "    axes[i, j].set_title(batch[1][index], fontdict=title_font)\n",
    "\n",
    "    j += 1\n",
    "    \n",
    "    if j==7:\n",
    "        i = 1\n",
    "        j = 0\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scaling The Dataset <a id = 5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's check the data values' minimum and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.25613Z",
     "iopub.status.busy": "2023-06-03T09:11:55.25561Z",
     "iopub.status.idle": "2023-06-03T09:11:55.262705Z",
     "shell.execute_reply": "2023-06-03T09:11:55.261498Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.256095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Data Minimum: {batch[0].min()}\")\n",
    "print(f\"Data Maximum: {batch[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like most of the times the range of values is between 0 and 255.</br>\n",
    "Now we can scale the data by deviding its values by 255 to make the learning process faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this by using the map function in data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.265521Z",
     "iopub.status.busy": "2023-06-03T09:11:55.265118Z",
     "iopub.status.idle": "2023-06-03T09:11:55.31531Z",
     "shell.execute_reply": "2023-06-03T09:11:55.314197Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.265485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255., y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've created the data scaler and the scaler is now embedded in the data pypeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the next batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.317621Z",
     "iopub.status.busy": "2023-06-03T09:11:55.317195Z",
     "iopub.status.idle": "2023-06-03T09:11:55.530926Z",
     "shell.execute_reply": "2023-06-03T09:11:55.529777Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.317585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch = data.as_numpy_iterator().next()\n",
    "\n",
    "print(f\"Data Minimum: {batch[0].min()}\")\n",
    "print(f\"Data Maximum: {batch[0].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, this won't make any change in the images appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/val split <a id = 6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the train and validation data is a package of data named train we should split that to validate the model when training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.533662Z",
     "iopub.status.busy": "2023-06-03T09:11:55.532953Z",
     "iopub.status.idle": "2023-06-03T09:11:55.543457Z",
     "shell.execute_reply": "2023-06-03T09:11:55.542191Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.53362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data)*0.875)\n",
    "validation_size = int(len(data)*0.125)\n",
    "\n",
    "print(f\"The train dataset size will be {train_size}.\")\n",
    "print(f\"The validation dataset size will be {validation_size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.547473Z",
     "iopub.status.busy": "2023-06-03T09:11:55.545338Z",
     "iopub.status.idle": "2023-06-03T09:11:55.566271Z",
     "shell.execute_reply": "2023-06-03T09:11:55.565075Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.547443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "validation = data.skip(train_size).take(validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training utils <a id = 7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a deep neural network, we define a variable taking the whole model in it and then add settings and features to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.568624Z",
     "iopub.status.busy": "2023-06-03T09:11:55.567936Z",
     "iopub.status.idle": "2023-06-03T09:11:55.587586Z",
     "shell.execute_reply": "2023-06-03T09:11:55.586044Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.568587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(input_shape, optimizer, loss, metrics):\n",
    "    \"\"\"\n",
    "    This is a Python function that compiles and returns a neural network model using the Keras library.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple)             The shape of the input data for the model.\n",
    "        optimizer (str or callable)     The optimizer to use for training the model.\n",
    "        loss (str or callable)          The loss function to use during training.\n",
    "        metrics (list)                  The list of evaluation metrics for the model.\n",
    "\n",
    "    Returns:\n",
    "        model ()                        The compiled Keras model object that can be used for training.\n",
    "    \"\"\"\n",
    "        \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional and pooling layers\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), strides=1, activation=\"relu\",\n",
    "                     padding=\"same\", input_shape=(48, 48, 1)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides=1, activation=\"relu\",\n",
    "                     padding=\"same\"))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Convolutional and pooling layers\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), strides=1, activation=\"relu\",\n",
    "                     padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), strides=1, activation=\"relu\",\n",
    "                     padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten and dense layer\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Flatten and dense layer\n",
    "    \n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Final layer\n",
    "    \n",
    "    model.add(Dense(7, activation=\"softmax\"))\n",
    "    \n",
    "    # Compiler\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.592804Z",
     "iopub.status.busy": "2023-06-03T09:11:55.591875Z",
     "iopub.status.idle": "2023-06-03T09:11:55.60476Z",
     "shell.execute_reply": "2023-06-03T09:11:55.603682Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.592758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data, epochs, validation_data, callbacks):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    This is a Python function that trains a given neural network model\n",
    "    on the provided training data and returns the training history.\n",
    "\n",
    "    Args:\n",
    "        model (tensorflow.keras model)          The neural network model object to train.\n",
    "        train_data (numpy.ndarray)              The training data to use for training the model.\n",
    "        train_target (numpy.ndarray)            The target values for the training data.\n",
    "        epochs (int)                            The number of epochs to train the model.\n",
    "        validation_data (numpy.ndarray)         The validation data to use for evaluation.\n",
    "        callbacks (list)                        A list of Keras callbacks to use during training.\n",
    "\n",
    "    Returns:\n",
    "        history ()                              The training history object that contains information\n",
    "                                                about the training and validation metrics over each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    history = model.fit(train_data,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=validation_data,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define some callbacks to get more insights when training or validating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.607169Z",
     "iopub.status.busy": "2023-06-03T09:11:55.606748Z",
     "iopub.status.idle": "2023-06-03T09:11:55.621921Z",
     "shell.execute_reply": "2023-06-03T09:11:55.620822Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.607134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chemins des répertoires pour le modèle, les checkpoints et l'historique\n",
    "model_base_dir = os.path.join(\"..\", \"model\")\n",
    "checkpoints_dir = os.path.join(model_base_dir, \"checkpoints\")\n",
    "history_dir = os.path.join(model_base_dir, \"history\")\n",
    "\n",
    "os.makedirs(model_base_dir, exist_ok=True)\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "class TrainingCallbacks(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        print(\"Starting training ...\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        print(f\"Epoch {epoch + 1} completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        total_time = time.time() - self.start_time\n",
    "        print(f\"Training finished in {total_time:.2f} seconds\")\n",
    "        \n",
    "logs_cb = callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=os.path.join(checkpoints_dir, \"model.h5\"),\n",
    "                                       save_best_only=True,\n",
    "                                       monitor=\"val_accuracy\")\n",
    "        \n",
    "callbacks_list = [TrainingCallbacks(), logs_cb, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model <a id = 8></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the function above, now we can builld the architecture defined in the function and parameters determined as the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.624737Z",
     "iopub.status.busy": "2023-06-03T09:11:55.624225Z",
     "iopub.status.idle": "2023-06-03T09:11:55.937437Z",
     "shell.execute_reply": "2023-06-03T09:11:55.936606Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.624699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = get_compiled_model((48, 48, 1),\n",
    "                           optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                           loss=\"sparse_categorical_crossentropy\",\n",
    "                           metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's better to plot the architecture to understand the network better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:55.938915Z",
     "iopub.status.busy": "2023-06-03T09:11:55.938549Z",
     "iopub.status.idle": "2023-06-03T09:11:56.236304Z",
     "shell.execute_reply": "2023-06-03T09:11:56.235271Z",
     "shell.execute_reply.started": "2023-06-03T09:11:55.938881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True,\n",
    "           show_layer_names=False,\n",
    "           expand_nested=True,\n",
    "           rankdir=\"TB\",\n",
    "           dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training <a id = 9></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model and save its information in a variable to check it out later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:11:56.239Z",
     "iopub.status.busy": "2023-06-03T09:11:56.238203Z",
     "iopub.status.idle": "2023-06-03T09:13:17.912431Z",
     "shell.execute_reply": "2023-06-03T09:13:17.911352Z",
     "shell.execute_reply.started": "2023-06-03T09:11:56.23896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = train_model(model,\n",
    "                      train_data=train,\n",
    "                      epochs=60,\n",
    "                      validation_data=validation,\n",
    "                      callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle final et de l'historique dans ../model\n",
    "# (en plus du meilleur modèle sauvegardé automatiquement par ModelCheckpoint)\n",
    "model.save(os.path.join(model_base_dir, \"final_model.keras\"))\n",
    "model.save(os.path.join(model_base_dir, \"final_model.h5\"))\n",
    "\n",
    "with open(os.path.join(history_dir, \"history.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we should save the model's history data in a readable format too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:13:17.91504Z",
     "iopub.status.busy": "2023-06-03T09:13:17.914351Z",
     "iopub.status.idle": "2023-06-03T09:13:17.92258Z",
     "shell.execute_reply": "2023-06-03T09:13:17.921436Z",
     "shell.execute_reply.started": "2023-06-03T09:13:17.914972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The model's history can be saved using this block of code.\n",
    "\n",
    "\"\"\"with open(os.path.join(\"history\", \"history.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Loading The Model and its History <a id = 10></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firslty, we open the history file we have saved after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle et de l'historique depuis ../model\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger le meilleur modèle sauvegardé par le callback\n",
    "model = load_model(os.path.join(\"..\", \"model\", \"checkpoints\", \"model.h5\"))\n",
    "# ou pour charger le modèle final\n",
    "# model = load_model(os.path.join(\"..\", \"model\", \"final_model.keras\"))\n",
    "\n",
    "# Charger l'historique d'entraînement\n",
    "with open(os.path.join(\"..\", \"model\", \"history\", \"history.pkl\"), \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\"\"\"\n",
    "\n",
    "# Si 'history' est un objet History (après entraînement dans la même session),\n",
    "# convertir en dict. Si c'est déjà un dict chargé depuis pickle, on ne touche pas.\n",
    "try:\n",
    "    history = history.history\n",
    "except AttributeError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:05.251131Z",
     "iopub.status.busy": "2023-06-03T09:14:05.250749Z",
     "iopub.status.idle": "2023-06-03T09:14:05.255885Z",
     "shell.execute_reply": "2023-06-03T09:14:05.254922Z",
     "shell.execute_reply.started": "2023-06-03T09:14:05.251098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The model can be loaded and the model's history can be read using this block of code.\n",
    "\n",
    "\n",
    "\"\"\"model = load_model(os.path.join(\"checkpoints\", \"model.h5\"))\n",
    "\n",
    "with open(os.path.join(\"history\", \"history.pkl\"), \"rb\") as f:\n",
    "    history = pickle.load(f)\"\"\"\n",
    "\n",
    "history = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have access the data saved during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:08.477631Z",
     "iopub.status.busy": "2023-06-03T09:14:08.47698Z",
     "iopub.status.idle": "2023-06-03T09:14:08.494873Z",
     "shell.execute_reply": "2023-06-03T09:14:08.493661Z",
     "shell.execute_reply.started": "2023-06-03T09:14:08.477595Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plotting The Models's Loss and Accuracy <a id = 11></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the model performs in both training and validation datasets through epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:11.00256Z",
     "iopub.status.busy": "2023-06-03T09:14:11.002198Z",
     "iopub.status.idle": "2023-06-03T09:14:11.414837Z",
     "shell.execute_reply": "2023-06-03T09:14:11.413738Z",
     "shell.execute_reply.started": "2023-06-03T09:14:11.002528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "axes_font = {\"family\" : \"arial\", \"color\" : \"#023553\", \"weight\" : \"bold\", \"size\" : 12}\n",
    "\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "\n",
    "plt.plot(history[\"loss\"], color=\"#3BB47E\", label=\"Training loss\")\n",
    "plt.plot(history[\"val_loss\"], color=\"#FF605C\", label=\"Validation Loss\")\n",
    "\n",
    "plt.xticks(range(len(history[\"loss\"])))\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Loss vs Epochs\", fontdict = title_font)\n",
    "plt.xlabel(\"Epoch Number\", fontdict = axes_font)\n",
    "plt.ylabel(\"Loss\", fontdict = axes_font)\n",
    "\n",
    "plt.grid(True, axis=\"x\", alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "max_val_acc_row_index = history_df[history_df[\"val_accuracy\"] == max(history_df[\"val_accuracy\"])].index[-1]\n",
    "\n",
    "plt.scatter(max_val_acc_row_index,\n",
    "            history_df.loc[max_val_acc_row_index, \"val_loss\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's obvious that model suffers from overfitting problem.</br>\n",
    "This can be the result of many issues, which will be addressed later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check its loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:13.203175Z",
     "iopub.status.busy": "2023-06-03T09:14:13.202793Z",
     "iopub.status.idle": "2023-06-03T09:14:13.598934Z",
     "shell.execute_reply": "2023-06-03T09:14:13.597927Z",
     "shell.execute_reply.started": "2023-06-03T09:14:13.203141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "axes_font = {\"family\" : \"arial\", \"color\" : \"#023553\", \"weight\" : \"bold\", \"size\" : 12}\n",
    "\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "\n",
    "plt.plot(history[\"accuracy\"], color=\"#3BB47E\", label=\"Training accuracy\")\n",
    "plt.plot(history[\"val_accuracy\"], color=\"#FF605C\", label=\"Validation accuracy\")\n",
    "\n",
    "plt.xticks(range(len(history[\"accuracy\"])))\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.title(\"Accuracy vs Epochs\", fontdict = title_font)\n",
    "plt.xlabel(\"Epoch Number\", fontdict = axes_font)\n",
    "plt.ylabel(\"Accuracy\", fontdict = axes_font)\n",
    "\n",
    "plt.grid(True, axis=\"x\", alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "plt.scatter(max_val_acc_row_index,\n",
    "            history_df.loc[max_val_acc_row_index, \"val_accuracy\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model's Performance Evaluation <a id = 12></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to check how the model performs on the testing dataset.</br>\n",
    "For this goal we will evaluate the model using three metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:14.688958Z",
     "iopub.status.busy": "2023-06-03T09:14:14.688118Z",
     "iopub.status.idle": "2023-06-03T09:14:14.703594Z",
     "shell.execute_reply": "2023-06-03T09:14:14.702548Z",
     "shell.execute_reply.started": "2023-06-03T09:14:14.688924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy = Accuracy()\n",
    "categorical_accuracy = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't load the test dataset in the model, so we should build a data pipeline for that.</br>\n",
    "And then we should update the metrics for each batch of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:15.403839Z",
     "iopub.status.busy": "2023-06-03T09:14:15.403141Z",
     "iopub.status.idle": "2023-06-03T09:14:18.772537Z",
     "shell.execute_reply": "2023-06-03T09:14:18.771507Z",
     "shell.execute_reply.started": "2023-06-03T09:14:15.403798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_directory = os.path.join(\"/kaggle/input/fer2013\", \"test\")\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(test_directory,\n",
    "                                                           image_size=(48, 48),\n",
    "                                                           batch_size=64,\n",
    "                                                           color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:18.775171Z",
     "iopub.status.busy": "2023-06-03T09:14:18.774488Z",
     "iopub.status.idle": "2023-06-03T09:14:34.764135Z",
     "shell.execute_reply": "2023-06-03T09:14:34.76306Z",
     "shell.execute_reply.started": "2023-06-03T09:14:18.775131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "\n",
    "    test_data, test_target = batch\n",
    "    test_target = to_categorical(test_target, num_classes=num_classes)\n",
    "\n",
    "    test_target_pred = model.predict(test_data, verbose=0)\n",
    "\n",
    "    categorical_accuracy.update_state(test_target, test_target_pred)\n",
    "    accuracy.update_state(test_target, test_target_pred)\n",
    "\n",
    "    test_target_pred_labels = np.argmax(test_target_pred, axis=1)\n",
    "\n",
    "    batch_confusion_matrix = sk_confusion_matrix(np.argmax(test_target, axis=1), test_target_pred_labels, labels=range(num_classes))\n",
    "    confusion_matrix += batch_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:34.766864Z",
     "iopub.status.busy": "2023-06-03T09:14:34.766463Z",
     "iopub.status.idle": "2023-06-03T09:14:34.781598Z",
     "shell.execute_reply": "2023-06-03T09:14:34.780146Z",
     "shell.execute_reply.started": "2023-06-03T09:14:34.766829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Testing Results\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(f\"Accuracy               {(accuracy.result()*100):.4f}\")\n",
    "print(f\"Categorical Accuracy   {(categorical_accuracy.result()*100):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the testing results, there are a couple of observations:\n",
    "\n",
    "**Accuracy**</br>\n",
    "\n",
    "The overall accuracy of 77.7276% indicates that the model is correctly predicting the facial expression for approximately 77.7% of the test samples.</br>\n",
    "However, it's important to consider the class distribution to gain a deeper understanding of the model's performance.\n",
    "\n",
    "**Categorical Accuracy**</br>\n",
    "\n",
    "The categorical accuracy of 30.3706% suggests that the model is struggling to accurately classify the test samples into their respective facial expression categories.</br>\n",
    "This metric measures the percentage of samples for which the highest predicted class matches the true class.\n",
    "\n",
    "The low categorical accuracy indicates that the model might be biased towards the majority class(es) or facing difficulties in distinguishing between the different facial expressions, especially the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the confusion matrix to understand how the model performed the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T09:14:34.784317Z",
     "iopub.status.busy": "2023-06-03T09:14:34.7834Z",
     "iopub.status.idle": "2023-06-03T09:14:35.308715Z",
     "shell.execute_reply": "2023-06-03T09:14:35.307714Z",
     "shell.execute_reply.started": "2023-06-03T09:14:34.784278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "title_font = {\"family\" : \"arial\", \"color\" : \"k\", \"weight\" : \"bold\", \"size\" : 14}\n",
    "axes_font = {\"family\" : \"arial\", \"color\" : \"#023553\", \"weight\" : \"bold\", \"size\" : 12}\n",
    "\n",
    "normalized_confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "heatmap = sns.heatmap(normalized_confusion_matrix, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Labels\", fontdict=axes_font)\n",
    "ax.set_ylabel(\"True Labels\", fontdict=axes_font)\n",
    "ax.set_title(\"Confusion Matrix\", fontdict=title_font)\n",
    "\n",
    "ax.xaxis.set_ticklabels(expressions_list)\n",
    "ax.yaxis.set_ticklabels(expressions_list)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix, a few observations can be made:\n",
    "\n",
    "**Majority Class Bias**</br>\n",
    "\n",
    "The diagonal elements of the confusion matrix (from top left to bottom right) represent the correctly classified samples.</br>\n",
    "It appears that the model performs relatively well in predicting the \"happy\" class, as it has the highest percentage (64%) of correct predictions among all the classes.</br>\n",
    "On the other hand, the model struggles to accurately classify the \"neutral\" and \"sad\" classes, as indicated by lower percentages in the corresponding diagonal elements.\n",
    "\n",
    "**Misclassifications**</br>\n",
    "\n",
    "The off-diagonal elements of the confusion matrix represent misclassifications.</br>\n",
    "For example, the model tends to confuse \"angry\" samples with \"disgust,\" \"fear,\" and \"happy\" classes.</br>\n",
    "Similarly, \"sad\" samples are often misclassified as \"angry,\" \"disgust,\" and \"fear.\"\n",
    "\n",
    "**Imbalanced Misclassifications**</br>\n",
    "\n",
    "It's worth noting that the misclassifications are not evenly distributed.</br>\n",
    "For instance, the \"neutral\" class has a relatively high proportion of misclassifications, particularly being confused with \"disgust,\" \"fear,\" and \"sad.\"\n",
    "\n",
    "Based on the confusion matrix, it seems that the model struggles to accurately differentiate between certain facial expressions, especially those with similar visual characteristics.</br>\n",
    "This highlights the need to further fine-tune the model, consider data augmentation techniques, and potentially explore more complex architectures or advanced techniques to enhance its performance in distinguishing between these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Content](#0)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 786787,
     "sourceId": 1351797,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30497,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
